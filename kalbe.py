# -*- coding: utf-8 -*-
"""Kalbe.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lxq9y-4Rvun_fJybd6s0lh6Y2cKRh_lR

Import Library
---
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pmdarima as pm

from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.stattools import adfuller
from math import sqrt

import warnings
warnings.simplefilter("ignore")

"""Load Dataset
---
"""

data_cust = pd.read_csv('Case Study - Customer.csv', delimiter=';')
data_prod = pd.read_csv('Case Study - Product.csv', delimiter=';')
data_store = pd.read_csv('Case Study - Store1.csv', delimiter=';')
data_trx = pd.read_csv('Case Study - Transaction.csv', delimiter=';')

pd.set_option('display.max_columns', None)

df_cust = data_cust.copy()
df_prod = data_prod.copy()
df_store = data_store.copy()
df_trx = data_trx.copy()

df_cust.shape, df_prod.shape, df_store.shape, df_store.shape, df_trx.shape

"""Data Cleaning
---

Tabel Customer
"""

df_cust.head(3)

#ubah tanda koma (,) dengan titik (.)
df_cust['Income'] = df_cust['Income'].replace('[,]', '.', regex=True).astype(float)

df_cust.info()

df_cust.isnull().sum()

#karena null value sedikit, maka akan di drop
df_cust=df_cust.dropna(subset='Marital Status')
df_cust.isna().sum()

df_cust.duplicated().sum()

"""Tabel Produk"""

df_prod.head(3)

df_prod.info()

df_prod.duplicated().sum()

"""Tabel Store"""

df_store.head(3)

df_store.info()

df_store.duplicated().sum()

"""Tabel Transaksi"""

df_trx.head(3)

df_trx.info()

#ubah dtype date
df_trx['Date'] = pd.to_datetime(df_trx['Date'])

#cek data duplikat pada value 'TransactionID'
value_counts = df_trx['TransactionID'].value_counts()
duplicates = value_counts[value_counts > 1]

print(duplicates)

#cek salah satu value yang memiliki duplikat
df_trx[df_trx['TransactionID'] == 'TR42197']

"""Karena terdapat satu TransactionID dengan nilai yang berbeda pada CustomerID, Date, ProductID, Price, Qty, TotalAmount, StoreID. Diasumsikan terdapat kesalahan input sehingga data yang akan dipertahankan adalah data dengan date terkini."""

# Mengurutkan DataFrame berdasarkan kolom "date" secara menurun (descending)
df_trx.sort_values(by='Date', ascending=False, inplace=True)

# Menghapus duplikat berdasarkan kolom "transaction id", hanya mempertahankan yang terbaru
df_trx.drop_duplicates(subset='TransactionID', keep='first', inplace=True)

value_counts = df_trx['TransactionID'].value_counts()
duplicates = value_counts[value_counts > 1]

print(duplicates)

df_trx.duplicated().sum()

df_trx['Hari'] = df_trx['Date'].dt.day
df_trx['Bulan'] = df_trx['Date'].dt.month

df_trx.sample(3)

"""Menggabungkan semua tabel
---
"""

df_merge = pd.merge(df_trx, df_cust, on=['CustomerID'])
df_merge = pd.merge(df_merge, df_prod.drop(columns= ['Price']), on=['ProductID'])
df_merge = pd.merge(df_merge, df_store, on=['StoreID'])

df_merge.head()

#df_merge.to_excel('kalbe_table_base.xlsx')

"""Forecasting Data Preparation
---
"""

df_forecast =  df_merge.groupby('Date').agg({
    'Qty' : 'sum'
}).reset_index()

df_forecast

# Ubah indeks DataFrame menjadi kolom 'date'
df_forecast.set_index('Date', inplace=True)

"""Check Stationarity
--
"""

#Addressing Seasonality

decomposed = seasonal_decompose(df_forecast)
plt.figure(figsize=(8,8))

plt.subplot(311)
decomposed.trend.plot(ax=plt.gca())
plt.title('Trend')

plt.subplot(312)
decomposed.seasonal.plot(ax=plt.gca())
plt.title('Seasonality')

plt.subplot(313)
decomposed.resid.plot(ax=plt.gca())
plt.title('Residuals')

plt.tight_layout()

"""Tidak terlihat adanya pattern dalam trend maupun seasonality"""

# Rolling statistics

rollmean = df_forecast.rolling(12).mean()
rollstd = df_forecast.rolling(12).std()

# Membuat gambar dan subplot
plt.figure(figsize=(16,7))

# Plot rolling statistics
plt.plot(df_forecast.index, df_forecast, color='blue', label='Original')
plt.plot(rollmean.index, rollmean, color='red', label='Rolling Mean')
plt.plot(rollstd.index, rollstd, color='black', label='Rolling Std')

# Menambahkan legenda dan judul
plt.legend(loc='best')
plt.title('Rolling Mean & Standard Deviation')

# Mengatur label sumbu x sebagai tanggal
plt.xlabel('Date')

# Menampilkan plot
plt.show()

"""tidak terlihat adanya pattern tertentu"""

#Dickey Fuller Test

df_test = adfuller(df_forecast['Qty'])
adf = df_test[0]
pval = df_test[1]

print('ADF Statistics : ', adf)
print('P Value : ', pval)
print('Critical Values:')
for key, value in df_test[4].items():
    print(f'   {key}, {value}')

"""P-value < 0.05 menunjukan data tergolong stationary dan dapat digunakan untuk ARiMA model

ARIMA model
--

Split Data
--
"""

#split data menjadi data train dan data test
cut_off= round(df_forecast.shape[0] * 0.9)
df_train = df_forecast[:cut_off]
df_test = df_forecast[cut_off:]
df_train.shape, df_test.shape

df_train

df_test

#plt.figure(figsize=(20,5))
#sns.lineplot(data= df_train, x= df_train['Date'], y= df_train['Qty']);
#sns.lineplot(data= df_test, x= df_test['Date'], y= df_test['Qty']);

# Plot ACF dengan default method
plot_acf(df_train['Qty'], lags=30)
plt.xlabel('Lag')
plt.ylabel('Autocorrelation')
plt.title('Autocorrelation Function (ACF)')
plt.show()

# Plot PACF dengan ywm method
plot_pacf(df_train['Qty'], lags=30, method='ywm')
plt.xlabel('Lag')
plt.ylabel('Partial Autocorrelation')
plt.title('Partial Autocorrelation Function (PACF)')
plt.show()

# ARIMA Order (p, d, q)
order = (40, 2, 1)

# Membuat model ARIMA dengan data pelatihan
arima_model = ARIMA(df_train['Qty'], order=order)
arima_model = arima_model.fit()

# Mendapatkan peramalan untuk data pengujian
get_forecast = arima_model.get_forecast(steps=len(df_test))
forecast = get_forecast.conf_int()
forecast['predictions'] = arima_model.predict(start=forecast.index[0], end=forecast.index[-1])

# Menyesuaikan indeks hasil peramalan dengan indeks data pengujian
forecast.index = df_test.index
forecast_pred = forecast['predictions']

# Visualisasi hasil
plt.figure(figsize=(10, 6))
plt.plot(df_train.index, df_train['Qty'], color='blue', label='Data Pelatihan')
plt.plot(df_test.index, df_test['Qty'], color='red', label='Data Pengujian')
plt.plot(forecast_pred, color='yellow', label='Prediksi ARIMA')
plt.title('Peramalan Penjualan')
plt.legend()
plt.show()

plt.figure(figsize=(16, 6))
plt.plot(forecast_pred, color='green', label='Predicted Values')
plt.title('Estimated Quantity Sold')
plt.legend()
plt.show()

mean_qty = int(round(forecast_pred).mean())
print(f"Mean quantity sold: {mean_qty}")

sales_by_product = df_merge.groupby(['ProductID', 'Product Name', 'Date'])[['Qty']].sum()
sales_by_product = sales_by_product.reset_index()

forecast_dataframe = pd.DataFrame()

for product_name, group in sales_by_product.groupby('Product Name'):
    forecast_df_dum = group[['Date', 'Qty']]
    forecast_df_dum = forecast_df_dum.groupby('Date')[['Qty']].sum().reindex(pd.date_range(start='2022-01-01', end='2022-12-31'), fill_value=0)

    model = ARIMA(forecast_df_dum['Qty'], order=(40, 2, 1))
    model_fit = model.fit()
    forecast_period = df_test.shape[0]

    forecast = model_fit.forecast(steps=forecast_period)
    forecast_dataframe[product_name] = forecast.values

forecast_dataframe.head()

mean_qty_sold = round(forecast_dataframe).mean()
print(f"Mean Quantity sold:{mean_qty_sold}")

predicted_values = forecast_pred
actual_values = df_test

# Calculate RMSE
rmse = np.sqrt(mean_squared_error(actual_values, predicted_values))

# Calculate MAE
mae = mean_absolute_error(actual_values, predicted_values)

print("RMSE:", rmse)
print("MAE:", mae)

"""Clustering
---
"""

df_merge.head()

df_cluster = df_merge.groupby(['CustomerID']).agg({
    'TransactionID' : 'count',
    'Qty' : 'sum',
    'TotalAmount' : 'sum'
}).reset_index()

df_cluster.head()

X = df_cluster.iloc[:, -2:]

num_clusters = 3

k_means = KMeans(n_clusters=num_clusters, n_init=12)
k_means.fit(X)
labels = k_means.labels_

df_cluster["Labels"] = labels
df_cluster.head()

df_cluster.groupby('Labels').mean()

plt.figure(figsize=(10, 8))
sns.scatterplot(x=df_cluster['Qty'], y=df_cluster['TotalAmount'], hue=df_cluster['Labels'], palette=['g', 'r', 'b'])
plt.title('Customer Segmentation by Quantity and Total Amount')
plt.legend()
plt.show()

silhouette_score(X, labels)



